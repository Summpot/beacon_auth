name: Deploy (Cloudflare Worker)

on:
  push:
    branches:
      - main
    paths:
      - crates/beacon-worker/**
      - crates/beacon-core/**
      - Cargo.toml
      - Cargo.lock
      - wrangler.toml
      - src/**
      - public/**
      - package.json
      - pnpm-lock.yaml
      - rsbuild.config.ts
      - tsconfig.json
      - .github/workflows/deploy-cloudflare.yml
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: cloudflare-deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  deploy-worker:
    name: Deploy beacon-worker (API + Assets)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: wasm32-unknown-unknown

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'pnpm'

      - name: Install worker-build from subtree
        uses: baptiste0928/cargo-install@v3
        with:
          crate: worker-build
          args: --path ./thirdparty/worker-rs/worker-build

      - name: Install dependencies (frontend)
        run: pnpm install --frozen-lockfile

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-wasm-${{ hashFiles('**/Cargo.lock') }}

      - name: Install Wrangler CLI
        run: |
          npm install -g wrangler@4
          wrangler --version

      - name: Resolve D1 id + generate wrangler.ci.toml
        id: wrangler_ci
        uses: actions/github-script@v7
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          D1_DATABASE_ID: ${{ secrets.CLOUDFLARE_WORKER_D1_DATABASE_ID }}
          D1_DATABASE_NAME: ${{ vars.CLOUDFLARE_WORKER_D1_DATABASE_NAME || 'beacon-auth' }}
          BASE_URL: ${{ secrets.CLOUDFLARE_WORKER_BASE_URL }}
        with:
          script: |
            const fs = require('node:fs');
            const path = require('node:path');
            const cp = require('node:child_process');

            const repoRoot = process.env.GITHUB_WORKSPACE;
            if (!repoRoot) {
              throw new Error('GITHUB_WORKSPACE is not set.');
            }

            const wranglerTomlPath = path.join(repoRoot, 'wrangler.toml');
            process.chdir(repoRoot);

            const wranglerTomlRaw = fs.readFileSync(wranglerTomlPath, 'utf8');
            const nameMatch = wranglerTomlRaw.match(/^name\s*=\s*"([^"]+)"\s*$/m);
            const workerName = nameMatch ? String(nameMatch[1]).trim() : '';
            if (!workerName) {
              throw new Error('Could not resolve Worker name from wrangler.toml (expected: name = "...")');
            }

            const d1IdFromEnv = (process.env.D1_DATABASE_ID || '').trim();
            const d1Name = (process.env.D1_DATABASE_NAME || 'beacon-auth').trim();
            const baseUrlFromEnv = (process.env.BASE_URL || '').trim();
            const accountIdFromEnv = (process.env.CLOUDFLARE_ACCOUNT_ID || '').trim();
            const token = (process.env.CLOUDFLARE_API_TOKEN || '').trim();

            if (!token) {
              throw new Error('CLOUDFLARE_API_TOKEN is not set (required).');
            }

            async function cfJson(url, init) {
              const res = await fetch(url, init);
              const text = await res.text();
              let json;
              try {
                json = JSON.parse(text);
              } catch {
                throw new Error(`Cloudflare API returned non-JSON (HTTP ${res.status}): ${text}`);
              }
              if (!res.ok || json?.success === false) {
                throw new Error(`Cloudflare API error (HTTP ${res.status}): ${text}`);
              }
              return json;
            }

            async function resolveAccountId() {
              if (accountIdFromEnv) return accountIdFromEnv;

              const headers = {
                Authorization: `Bearer ${token}`,
                'Content-Type': 'application/json',
              };

              try {
                const acc = await cfJson('https://api.cloudflare.com/client/v4/accounts?per_page=50', { headers });
                const list = Array.isArray(acc?.result) ? acc.result : [];
                if (list.length === 1 && list[0]?.id) return String(list[0].id).trim();
                if (list.length > 1 && list[0]?.id) {
                  console.log(
                    `CLOUDFLARE_ACCOUNT_ID not provided; multiple accounts visible (${list.length}). Using the first account: ${list[0].name ?? list[0].id}`,
                  );
                  return String(list[0].id).trim();
                }
              } catch (e) {
                console.log(`Account id auto-detect skipped: ${e?.message ?? e}`);
              }

              return '';
            }

            // If we can resolve an account id, export it so subsequent `wrangler` commands
            // (d1 list/create/execute, deploy) do not require an explicit secret.
            const resolvedAccountId = await resolveAccountId();
            if (resolvedAccountId) {
              core.exportVariable('CLOUDFLARE_ACCOUNT_ID', resolvedAccountId);
              console.log(`Using Cloudflare account id: ${resolvedAccountId}`);
            }

            async function resolveBaseUrl() {
              if (baseUrlFromEnv) return baseUrlFromEnv;

              const accountId = resolvedAccountId;
              if (!accountId) return '';

              const headers = {
                Authorization: `Bearer ${token}`,
                'Content-Type': 'application/json',
              };

              // Fall back to workers.dev (single Worker serves both UI + API).
              try {
                const url = `https://api.cloudflare.com/client/v4/accounts/${accountId}/workers/subdomain`;
                const sub = await cfJson(url, { headers });
                const subdomain = (sub?.result?.subdomain || '').trim();
                if (!subdomain) return '';

                return `https://${workerName}.${subdomain}.workers.dev`;
              } catch (e) {
                console.log(`workers.dev BASE_URL auto-detect skipped: ${e?.message ?? e}`);
              }

              return '';
            }

            function execJson(args) {
              const out = cp.execFileSync('wrangler', args, { encoding: 'utf8' });
              try {
                return JSON.parse(out);
              } catch (e) {
                throw new Error(`Failed to parse JSON from: wrangler ${args.join(' ')}\n${out}`);
              }
            }

            function asArray(data) {
              if (Array.isArray(data)) return data;
              if (data && Array.isArray(data.result)) return data.result;
              if (data && Array.isArray(data.databases)) return data.databases;
              return [];
            }

            function getId(item) {
              return (item?.uuid ?? item?.id ?? item?.database_id ?? '').toString().trim();
            }

            let d1Id = d1IdFromEnv;
            if (!d1Id) {
              const list = execJson(['d1', 'list', '--json']);
              for (const it of asArray(list)) {
                if (it?.name === d1Name) {
                  d1Id = getId(it);
                  break;
                }
              }

              if (!d1Id) {
                console.log(`D1 database '${d1Name}' not found; creating it...`);
                cp.execFileSync('wrangler', ['d1', 'create', d1Name], { stdio: 'inherit' });

                const list2 = execJson(['d1', 'list', '--json']);
                for (const it of asArray(list2)) {
                  if (it?.name === d1Name) {
                    d1Id = getId(it);
                    break;
                  }
                }
              }
            }

            if (!d1Id) {
              throw new Error(
                "Unable to resolve a D1 database id. Provide secrets.CLOUDFLARE_WORKER_D1_DATABASE_ID or set vars.CLOUDFLARE_WORKER_D1_DATABASE_NAME (defaults to 'beacon-auth').",
              );
            }

            const srcPath = wranglerTomlPath;
            let text = fs.readFileSync(srcPath, 'utf8');

            if (text.includes('REPLACE_WITH_D1_DATABASE_ID')) {
              text = text.replaceAll('REPLACE_WITH_D1_DATABASE_ID', d1Id);
            } else {
              const re = /^database_id\s*=\s*"[^"]*"\s*$/gm;
              if (!re.test(text)) throw new Error('Could not find D1 database_id entry in wrangler.toml');
              text = text.replace(re, `database_id = "${d1Id}"`);
            }

            // Align the CI config to the resolved database name.
            text = text.replace(/^database_name\s*=\s*"[^"]*"\s*$/gm, `database_name = "${d1Name}"`);

            // Keep repo defaults unless BASE_URL can be resolved.
            const resolvedBaseUrl = await resolveBaseUrl();
            if (resolvedBaseUrl) {
              const re = /^BASE_URL\s*=\s*"[^"]*"\s*$/gm;
              if (!re.test(text)) {
                throw new Error('Could not find BASE_URL entry in wrangler.toml');
              }
              text = text.replace(re, `BASE_URL = "${resolvedBaseUrl}"`);
            } else {
              console.log('BASE_URL not provided and could not be auto-detected; leaving repo default in wrangler.toml.');
              console.log('Tip: set secrets.CLOUDFLARE_WORKER_BASE_URL to your Worker custom domain origin if you need a stable issuer/redirect base.');
            }

            const outPath = path.join(repoRoot, 'wrangler.ci.toml');
            fs.writeFileSync(outPath, text, 'utf8');
            console.log(`Wrote ${outPath} (D1 name=${d1Name}, id=${d1Id})`);

            core.setOutput('worker_name', workerName);
            core.setOutput('d1_name', d1Name);
            core.setOutput('d1_id', d1Id);
            core.setOutput('resolved_base_url', resolvedBaseUrl || baseUrlFromEnv || '');

      - name: Apply D1 schema (idempotent)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: wrangler d1 execute DB --remote --yes --file crates/beacon-worker/migrations/0001_init.sql --config wrangler.ci.toml

      - name: Sync Worker secrets (optional)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          JWT_PRIVATE_KEY_DER_B64: ${{ secrets.CLOUDFLARE_WORKER_JWT_PRIVATE_KEY_DER_B64 }}
          GITHUB_CLIENT_ID: ${{ secrets.CLOUDFLARE_WORKER_GITHUB_CLIENT_ID }}
          GITHUB_CLIENT_SECRET: ${{ secrets.CLOUDFLARE_WORKER_GITHUB_CLIENT_SECRET }}
          GOOGLE_CLIENT_ID: ${{ secrets.CLOUDFLARE_WORKER_GOOGLE_CLIENT_ID }}
          GOOGLE_CLIENT_SECRET: ${{ secrets.CLOUDFLARE_WORKER_GOOGLE_CLIENT_SECRET }}
        shell: bash
        run: |
          set -euo pipefail

          put_secret() {
            local name="$1"
            local value="$2"
            if [ -n "$value" ]; then
              echo "Setting secret: $name"
              printf %s "$value" | wrangler secret put "$name" --config wrangler.ci.toml
            else
              echo "Skipping secret (not provided): $name"
            fi
          }

          put_secret JWT_PRIVATE_KEY_DER_B64 "${JWT_PRIVATE_KEY_DER_B64:-}"
          put_secret GITHUB_CLIENT_ID "${GITHUB_CLIENT_ID:-}"
          put_secret GITHUB_CLIENT_SECRET "${GITHUB_CLIENT_SECRET:-}"
          put_secret GOOGLE_CLIENT_ID "${GOOGLE_CLIENT_ID:-}"
          put_secret GOOGLE_CLIENT_SECRET "${GOOGLE_CLIENT_SECRET:-}"

      - name: Deploy worker
        id: deploy_worker
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail

          out_file="$(mktemp)"
          wrangler deploy --config wrangler.ci.toml 2>&1 | tee "$out_file"

          # Try to extract the workers.dev URL from `wrangler deploy` output.
          worker_url="$(grep -Eo 'https://[^ ]+\.workers\.dev' "$out_file" | head -n 1 || true)"
          if [ -z "$worker_url" ]; then
            host_only="$(grep -Eo '[A-Za-z0-9.-]+\.workers\.dev' "$out_file" | head -n 1 || true)"
            if [ -n "$host_only" ]; then
              worker_url="https://$host_only"
            fi
          fi

          if [ -n "$worker_url" ]; then
            echo "Detected Worker URL: $worker_url"
          else
            echo "Could not detect Worker URL from deploy output; Pages proxy step will fall back to resolved_base_url (if available)."
          fi

          echo "worker_url=$worker_url" >> "$GITHUB_OUTPUT"

      - name: Deploy Pages proxy (short *.pages.dev)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          PAGES_PROJECT: ${{ steps.wrangler_ci.outputs.worker_name }}
          WORKER_ORIGIN: ${{ steps.deploy_worker.outputs.worker_url || steps.wrangler_ci.outputs.resolved_base_url }}
        shell: bash
        run: |
          set -euo pipefail

          project="${PAGES_PROJECT:?PAGES_PROJECT is required}"
          upstream="${WORKER_ORIGIN:-}"
          if [ -z "$upstream" ]; then
            echo "::error::WORKER_ORIGIN is empty; could not infer Worker URL from deploy output (preferred) or resolved_base_url (fallback)."
            exit 1
          fi

          if [[ "$upstream" != http://* && "$upstream" != https://* ]]; then
            upstream="https://$upstream"
          fi

          tmp_dir="$(mktemp -d)"
          cat > "$tmp_dir/index.html" <<'HTML'
          <!doctype html>
          <meta charset="utf-8" />
          <meta name="viewport" content="width=device-width, initial-scale=1" />
          <title>BeaconAuth</title>
          <p>BeaconAuth Pages proxy.</p>
          HTML

          # Deploy a Pages project that reverse-proxies all requests to the Worker.
          # This keeps the short *.pages.dev domain in the browser while the Worker handles logic.
          cat > "$tmp_dir/_worker.js" <<JS
          const UPSTREAM_ORIGIN = ${upstream@Q};
          const UPSTREAM = new URL(UPSTREAM_ORIGIN);

          addEventListener('fetch', (event) => {
            event.respondWith(handle(event.request));
          });

          async function handle(request) {
            const url = new URL(request.url);
            const upstreamUrl = new URL(request.url);
            upstreamUrl.protocol = UPSTREAM.protocol;
            upstreamUrl.hostname = UPSTREAM.hostname;
            upstreamUrl.port = UPSTREAM.port;

            const headers = new Headers(request.headers);
            // Avoid forbidden/host-related header issues; the URL determines the upstream host.
            headers.delete('host');
            headers.delete('Host');
            headers.set('X-Forwarded-Host', url.host);
            headers.set('X-Forwarded-Proto', url.protocol.replace(':', ''));

            const init = {
              method: request.method,
              headers,
              redirect: 'manual',
              body: request.method === 'GET' || request.method === 'HEAD' ? undefined : request.body,
            };

            let resp = await fetch(new Request(upstreamUrl.toString(), init));

            // If the upstream sends absolute redirects back to *.workers.dev, rewrite them to this Pages host.
            const location = resp.headers.get('Location');
            if (location) {
              try {
                const locUrl = new URL(location, upstreamUrl);
                if (locUrl.hostname === UPSTREAM.hostname) {
                  locUrl.hostname = url.hostname;
                  locUrl.protocol = url.protocol;
                  const newHeaders = new Headers(resp.headers);
                  newHeaders.set('Location', locUrl.toString());
                  resp = new Response(resp.body, {
                    status: resp.status,
                    statusText: resp.statusText,
                    headers: newHeaders,
                  });
                }
              } catch {
                // ignore malformed Location header
              }
            }

            return resp;
          }
          JS

          echo "Ensuring Pages project exists: '$project'"
          if wrangler pages project list --json | jq -e --arg name "$project" '(if type=="array" then . else (.result // .projects // []) end) | any(.name == $name)' >/dev/null; then
            echo "Pages project '$project' already exists."
          else
            echo "Pages project '$project' not found; creating it (production branch: main)..."
            wrangler pages project create "$project" --production-branch "main"
          fi

          echo "Deploying Pages project '$project' (proxy -> $upstream)"
          # Run from the temp directory so Wrangler doesn't auto-detect this repo's wrangler.toml/git state.
          pushd "$tmp_dir" >/dev/null
          wrangler pages deploy . --project-name "$project" --branch "main"
          popd >/dev/null

          echo "Pages URL: https://$project.pages.dev" >> "$GITHUB_STEP_SUMMARY"

      